{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XeV4IbOogQmV"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'meteostat'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Point, Daily, Hourly\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'meteostat'"
          ]
        }
      ],
      "source": [
        "from meteostat import Point, Daily, Hourly\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxtnpL-4hpGd"
      },
      "outputs": [],
      "source": [
        "# Coordinates of Delhi\n",
        "delhi = Point(28.6139, 77.2090)\n",
        "# Hourly data from Jan to April 2024\n",
        "start_date = pd.to_datetime('2020-01-01')\n",
        "end_date = pd.to_datetime('2024-04-30')\n",
        "data = Hourly(delhi, start=start_date, end=end_date)\n",
        "df = data.fetch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8HT_CCahZZe",
        "outputId": "3000c14c-b41d-42e6-acd8-8087aca909e3"
      },
      "outputs": [],
      "source": [
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwgH88TyiBBu"
      },
      "outputs": [],
      "source": [
        "#Let’s sort and structure the time column:\n",
        "df = df.reset_index()\n",
        "df['time'] = pd.to_datetime(df['time'])\n",
        "df.set_index('time', inplace=True)\n",
        "df = df.sort_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJSt9mjSiTl-"
      },
      "outputs": [],
      "source": [
        "#Let’s resample to hourly data using mean() (safe for numeric weather):\n",
        "df_hourly = df.resample('1h').mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "Omz15Z_Bidw9",
        "outputId": "f444cb2d-c3ad-4556-a33a-781e87c34a92"
      },
      "outputs": [],
      "source": [
        "#Check for Nan values\n",
        "df_hourly.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2EZDkD0ipNe"
      },
      "outputs": [],
      "source": [
        "#Filling missing data\n",
        "df_filled = df_hourly.ffill()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "HOxRzFMNiyB1",
        "outputId": "b56465ea-5b05-403b-dd62-8b36b8aaf5ac"
      },
      "outputs": [],
      "source": [
        "#Visualize the Cleaned Data\n",
        "df_filled['temp'].plot(figsize=(14, 5), title=\"Hourly Temperature in Delhi\")\n",
        "plt.ylabel('Temperature (°C)')\n",
        "plt.xlabel('Time')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKSt0sJ4jBMl"
      },
      "outputs": [],
      "source": [
        "#Sace cleaned data\n",
        "df_filled.to_csv(\"delhi_hourly_weather_clean.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iGz-XgpobtL",
        "outputId": "36b12ea1-68a7-4f4e-9507-7e1a3a54134d"
      },
      "outputs": [],
      "source": [
        "df_cleaned = pd.read_csv(\"delhi_hourly_weather_clean.csv\", index_col='time', parse_dates=True)\n",
        "print(df_cleaned.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVdrUVtEo1pv",
        "outputId": "1ac48997-4cb2-4fe6-9c11-b1edcba5d3fc"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Data Preparation for regression\n",
        "# We'll use 'dwpt' (dew point) and 'rhum' (relative humidity) to predict 'temp' (temperature)\n",
        "\n",
        "X = df_cleaned[['dwpt', 'rhum']].values\n",
        "y = df_cleaned['temp'].values\n",
        "\n",
        "# Scale the features (X)\n",
        "scaler_X = MinMaxScaler()\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "\n",
        "# Scale the target variable (y)\n",
        "scaler_y = MinMaxScaler()\n",
        "# Reshape y to be a 2D array as required by MinMaxScaler\n",
        "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
        "\n",
        "# Save the scalers\n",
        "joblib.dump(scaler_X, 'linear_regression_scaler_X.pkl')\n",
        "joblib.dump(scaler_y, 'linear_regression_scaler_y.pkl')\n",
        "\n",
        "print(\"End\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9384c797",
        "outputId": "66702fca-a7f8-4309-ad76-e0adc741488d"
      },
      "outputs": [],
      "source": [
        "# Train a Linear Regression model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model on the training data\n",
        "model_train = LinearRegression()\n",
        "model_train.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on training and validation sets\n",
        "y_train_pred_scaled = model_train.predict(X_train)\n",
        "y_val_pred_scaled = model_train.predict(X_val)\n",
        "\n",
        "# Inverse transform the predictions and actual values to original scale\n",
        "y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled)\n",
        "y_val_pred = scaler_y.inverse_transform(y_val_pred_scaled)\n",
        "y_train_orig = scaler_y.inverse_transform(y_train)\n",
        "y_val_orig = scaler_y.inverse_transform(y_val)\n",
        "\n",
        "# Calculate metrics for training set\n",
        "train_mse = mean_squared_error(y_train_orig, y_train_pred)\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "train_r2 = r2_score(y_train_orig, y_train_pred)\n",
        "train_mape = np.mean(np.abs((y_train_orig - y_train_pred) / y_train_orig)) * 100\n",
        "\n",
        "# Calculate metrics for validation set\n",
        "val_mse = mean_squared_error(y_val_orig, y_val_pred)\n",
        "val_rmse = np.sqrt(val_mse)\n",
        "val_r2 = r2_score(y_val_orig, y_val_pred)\n",
        "val_mape = np.mean(np.abs((y_val_orig - y_val_pred) / y_val_orig)) * 100\n",
        "\n",
        "\n",
        "# Print the metrics\n",
        "print(\"Training Metrics:\")\n",
        "print(f\"  Mean Squared Error (MSE): {train_mse:.4f}\")\n",
        "print(f\"  Root Mean Squared Error (RMSE): {train_rmse:.4f}\")\n",
        "print(f\"  R-squared (R2): {train_r2:.4f}\")\n",
        "print(f\"  Mean Absolute Percentage Error (MAPE): {train_mape:.4f}%\")\n",
        "\n",
        "print(\"\\nValidation Metrics:\")\n",
        "print(f\"  Mean Squared Error (MSE): {val_mse:.4f}\")\n",
        "print(f\"  Root Mean Squared Error (RMSE): {val_rmse:.4f}\")\n",
        "print(f\"  R-squared (R2): {val_r2:.4f}\")\n",
        "print(f\"  Mean Absolute Percentage Error (MAPE): {val_mape:.4f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e9bc3c6",
        "outputId": "f1b922e3-a27e-474e-f436-12f4698d6e10"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# Data Preparation for LSTM\n",
        "# We'll use 'dwpt' (dew point) and 'rhum' (relative humidity) to predict 'temp' (temperature)\n",
        "\n",
        "X = df_cleaned[['dwpt', 'rhum']].values\n",
        "y = df_cleaned['temp'].values\n",
        "\n",
        "# Scale the features (X)\n",
        "scaler_X_lstm = MinMaxScaler()\n",
        "X_scaled_lstm = scaler_X_lstm.fit_transform(X)\n",
        "\n",
        "# Scale the target variable (y)\n",
        "scaler_y_lstm = MinMaxScaler()\n",
        "# Reshape y to be a 2D array as required by MinMaxScaler\n",
        "y_scaled_lstm = scaler_y_lstm.fit_transform(y.reshape(-1, 1))\n",
        "\n",
        "# Save the scalers\n",
        "joblib.dump(scaler_X_lstm, 'lstm_scaler_X.pkl')\n",
        "joblib.dump(scaler_y_lstm, 'lstm_scaler_y.pkl')\n",
        "\n",
        "\n",
        "# Function to create sequences for LSTM\n",
        "def create_sequences(X, y, time_steps=1):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        v = X[i:(i + time_steps)]\n",
        "        Xs.append(v)\n",
        "        ys.append(y[i + time_steps])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "# Define the number of time steps\n",
        "TIME_STEPS = 24 # Using 24 hours of data to predict the next hour\n",
        "\n",
        "X_sequences, y_sequences = create_sequences(X_scaled_lstm, y_scaled_lstm, TIME_STEPS)\n",
        "\n",
        "print(f\"Shape of X_sequences: {X_sequences.shape}\")\n",
        "print(f\"Shape of y_sequences: {y_sequences.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "76602e3a",
        "outputId": "b65be968-d547-4544-f7a6-e631c2ed1e75"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.metrics import MeanAbsolutePercentageError\n",
        "\n",
        "# Build the LSTM model\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(LSTM(units=50, return_sequences=True, input_shape=(X_sequences.shape[1], X_sequences.shape[2])))\n",
        "model_lstm.add(Dropout(0.2))\n",
        "model_lstm.add(LSTM(units=50, return_sequences=False))\n",
        "model_lstm.add(Dropout(0.2))\n",
        "model_lstm.add(Dense(units=1))\n",
        "\n",
        "# Compile the model\n",
        "model_lstm.compile(optimizer='adam', loss='mean_squared_error', metrics=[MeanAbsolutePercentageError()])\n",
        "model_lstm.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d9b0d001",
        "outputId": "99bfa474-ae74-4c03-c8e8-e0075052408f"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "\n",
        "# Split data into training and validation sets for LSTM\n",
        "X_train_lstm, X_val_lstm, y_train_lstm, y_val_lstm = train_test_split(X_sequences, y_sequences, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the LSTM model\n",
        "history = model_lstm.fit(X_train_lstm, y_train_lstm, epochs=20, batch_size=20, validation_split=0.2)\n",
        "\n",
        "# Visualize training and validation loss\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('LSTM Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Print final loss metrics\n",
        "print(\"\\nFinal Training Loss:\", history.history['loss'][-1])\n",
        "print(\"Final Validation Loss:\", history.history['val_loss'][-1])\n",
        "\n",
        "# Save the LSTM model\n",
        "model_lstm.save('lstm_model.h5')\n",
        "print(\"\\nLSTM model saved as 'lstm_model.h5'\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "VirtualEnviorment",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
